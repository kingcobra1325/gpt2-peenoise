# GPT2-Peenoise

A fine-tuned model from GPT2 that is trained in speaking basic tagalog. A small project to demonstrate AI/LLM training.

#### How to Use:

- Install dependencies from requirements.txt
    `pip install -r requirements.txt`
- Generate tagalog training data
    `python generate_training_data.py`
- Start the training
    `python start_training.py`
- Run the newly fine-tuned model
    `python chat_tagalog.py`

#

You can benchmark the trained model via
`evaluate_tagalog_gpt2.py`

Compare the newly fine-tuned model with the original GPT by running
`python chat_original.py`

Download the pre-finetuned model via [Google Drive](https://drive.google.com/file/d/1u0qJLLemv9-0IV7ooHoJO2X2Z-HKY3Si/view?usp=sharing)

#

Created by: [John Earl Cobar](https://github.com/kingcobra1325)
